<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="icon" href="favicon.png" type="image/x-icon">
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Research - Intelligent Multimedia Security Group</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="css/fotter.css">
  <link rel="stylesheet" href="css/stanford.css">

  <style type="text/css">
    ul {
      margin-left: 20px;
    }

    .media {
      border-bottom: solid 1px #E4E4E4;
      margin-bottom: 10px;
      margin-top: 10px;
    }

    .media .img-fluid {
      float: left;
      /* 左侧图片混排 */
      margin-right: 10px;
      /* 图片右端与文字的距离 */
      margin-bottom: 10px;
    }

    .media .body {
      padding-left: 220px;
      text-align: justify;
    }

    p {
      /* padding-left: 220px; */
      text-align: justify;
    }
  </style>

  <!-- <script defer src="https://use.fontawesome.com/releases/v5.9.0/js/all.js"></script> -->
</head>

<body class='page page-about'>
  <div id="main-menu-mobile" class="main-menu-mobile">
    <ul>
      <li class="menu-item-about">
        <a href="./home.html">
          <span>Home</span>
        </a>
      </li>

      <li class="menu-item-people">
        <a href="./people.html">
          <span>People</span>
        </a>
      </li>

      <li class="menu-item-publications">
        <a href="./publication.html">
          <span>Publication</span>
        </a>
      </li>

      <li class="menu-item-software  active">
        <a href="./research.html">
          <span>Research</span>
        </a>
      </li>

      <li class="menu-item-software">
        <a href="./info.html">
          <span>Information</span>
        </a>
      </li>
    </ul>
  </div>
  <div class="wrapper">
    <div class='header'>
      <div class="container">
        <h4 class="header-title">
          <a href="./home.html"><img src="./grouplogo.webp" style="max-width: 50%"></a>
          <!-- <a href="./home.html">Intelligent Multimedia Security Group</a> -->
        </h4>
        <div id="main-menu" class="main-menu">
          <ul>
            <li class="menu-item-about">
              <a href="./home.html">
                <span>Home</span>
              </a>
            </li>

            <li class="menu-item-people">
              <a href="./people.html">
                <span>People</span>
              </a>
            </li>

            <li class="menu-item-publications">
              <a href="./publication.html">
                <span>Publication</span>
              </a>
            </li>

            <li class="menu-item-software   active">
              <a href="./research.html">
                <span>Research</span>
              </a>
            </li>

            <li class="menu-item-software">
              <a href="./info.html">
                <span>Information</span>
              </a>
            </li>
          </ul>
        </div>
        <button id="toggle-main-menu-mobile" class="hamburger hamburger--slider" role="presentation"
          aria-label="mobile menu trigger">
          <span class="hamburger-box">
            <span class="hamburger-inner"></span>
          </span>
        </button>
      </div>
    </div>


    <div class="container mt-2">
      <div class="row">

        <div class="col-md-6">
          <div class="media">
            <h4><a href="research/maskedface.html" target="_blank"><strong>Masked Face Analysis</strong></a>
            </h4>
            <a class="img-fluid" href="research/maskedface.html" target="_blank"><img src="./img/research2/masked.webp"
                width="100%"></a>
            <p>
              <!-- <div class="body"> -->
              Many real-world applications like video surveillance and urban governance need to address the recognition
              of masked faces. In this research, we build the first large-scale MAsked FAce dataset (MAFA) in the world
              and propose novel solutions（e.g., LLE-CNNs, identity-diversity inpainting, de-occlusion distillation) to
              alleviate the effect of large occlusions in understanding masked faces, which are published in CVPR, ACM
              MM and IEEE TCSVT.
              <!-- </div> -->
            </p>
          </div>
        </div>
        <div class="col-md-6">
          <div class="media">
            <h4><a href="research/lowresface.html" target="_blank"><strong>Low-Resolution Face Recognition</strong></a>
            </h4>
            <a class="img-fluid" href="research/lowresface.html" target="_blank"><img
                src="./img/research2/low_resolution.webp" width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              Low-resolution face images lack sufficient information required for recognition and have a certain degree
              of ambiguity. In this research, we propose cross-quality knowledge distillation framework and devise a
              series of effective algorithms (e.g., selective knowledge distillation, bridge distillation, few-shot
              distillation, hybrid order relational distillation, etc) to facilitate low-resolution face recognition in
              the wild, which are published in IEEE TIP, ACM MM and AAAI.
            </p>
            <!-- </div> -->
          </div>
        </div>
        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="./research/deeptracking.html" target="_blank"><strong>Deep Visual Tracking</strong></a></h4>
            <a href="./research/deeptracking.html" target="_blank"><img src="./img/research2/deeptracking_indtro.webp"
                class="img-fluid service-img border" width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              Visual tracking plays an important role in many vision intelligence applications such as video
              surveilance, human-computer interaction, military and medical. In this research, we aim to propose
              effective solutions to facilitate the robustness, accuracy and efficiency of deep tracking in the
              real-world scenarios, which are publised in ACM MM, IEEE TNNLS and TIP, and have been deployed in some
              unmanned systems. Our solutions won the first places in two recent challenges (VisDrone-SOT@ICCV2019 and
              Anti-UAV@CVPR2020).
              <!-- </div> -->
            </p>
          </div>
        </div>
        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="research/conlearning.html" target="_blank"><strong>Controllable Representation
                  Learning</strong></a></h4>
            <a href="research/conlearning.html" target="_blank"><img
                src="./img/research2/Controllable_Representation_Learning.webp" class="img-fluid service-img border"
                width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              The uncontrollability in real scenario seriously limits the ability of the representation learning, such
              as the unexplainability for human, the vulnerability to  adversarial attack, the difficulty for learning
              from imperfect data, and other situations where the effective, fair and safe representation is very hard
              to learn.  We work on constructing a series of controllable representation learning algorithms (e.g.
              coupled-view learning, soft decision trees embedding, multi-granularity representation) to solve the above
              problems in real-world applications, which are publised in AAAI, ACM MM and IEEE TIP.
            </p>
            <!-- </div> -->
          </div>
        </div>

        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="research/fightingdeepfake.html" target="_blank"><strong>Understanding and Fighting Deepfake</strong></a></h4>
            <a href="research/fightingdeepfake.html" target="_blank"><img src="./img/research2/deepfake_detect.webp"
                class="img-fluid service-img border" width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              The rapid development of Deepfake makes it easier to generate high-fidelity and large quantities fake
              videos, which can cause serious influence on social public. In order to fight this, this research proposes
              a spaiotemporal method to detect Deepfake videos using deep 3-dimensional convolutional networks and LSTM.
              Experiments on DFDC dataset show our method can achieve competitive performance in Deepfake video
              detection task. Further, to make the detection system more understandable for human, how to make the model
              above more explainable is the next field to explore in the future.
              <!-- </div> -->
            </p>
          </div>
        </div>
        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="#" target="_blank"><strong>Collaborative Machine Learning</strong></a></h4>
            <a href="#" target="_blank"><img src="./img/research2/collaborative_machine_learning.webp"
                class="img-fluid service-img border" width="100%"></a>
            <p>
              When it comes to machine learning, the importance of data is self-evident, but most data is not wanted to
              be made public, a situation known as a "data island". In this research, we propose a controlled shared
              learning framework and design a series of effective algorithms (such as shared distillation, maximum local
              sharing, compression sharing) for machine learning under controlled conditions (data controlled, model
              controlled). These methods are suitable for various tasks (classification, semantic segmentation) and
              experiments on various datasets with excellent performance.
            </p>
            <!-- </div> -->
          </div>
        </div>

      </div>

    </div>
  </div>



  <div class="footer">
    <div class="container">
      <div class="footer-text text-center">
        Copyright© 2021 IMSG | 地址: 北京市海淀区杏石口路益园文创基地C11东段 <br>
        <!-- Address: East Section C11, Yiyuan Wenchuang Base, Xingshikou Road, Haidian District, Beijing -->
        <img src="./footer.png" width="18px"> 京公网安备 11011602000736号 &nbsp;&nbsp;&nbsp;&nbsp;<a
          href="http://beian.miit.gov.cn" target="_blank" style="color: white">京ICP备20030229号</a>
      </div>
    </div>
  </div>

  <script type="text/javascript"
    src="https://statweb.stanford.edu/~candes/js/scripts.min.bf1e1f7ae8e03db5f012356e825843facdff51c0a559cb0d27fe2bbe1db405c2.js"></script>


  <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
    integrity="sha256-pasqAKBDmFT4eHoN2ndd6lN370kFiGUFyTiUHWhU7k8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.15.0/umd/popper.min.js"
    integrity="sha256-fTuUgtT7O2rqoImwjrhDgbXTKUwyxxujIMRIK7TbuNU=" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>
  <script>
    $(function () { $('[data-toggle="tooltip"]').tooltip() })
  </script>

</body>

</html>
