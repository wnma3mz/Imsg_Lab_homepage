<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="icon" href="favicon.png" type="image/x-icon">
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Research - Intelligent Multimedia Security Group [智能多媒体安全学习之路]</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="css/fotter.css">
  <link rel="stylesheet" href="css/stanford.css">

  <style type="text/css">
    ul {
      margin-left: 20px;
    }

    .media {
      border-bottom: solid 1px #E4E4E4;
      margin-bottom: 10px;
      margin-top: 10px;
    }

    .media .img-fluid {
      float: left;
      /* 左侧图片混排 */
      margin-right: 10px;
      /* 图片右端与文字的距离 */
      margin-bottom: 10px;
    }

    .media .body {
      padding-left: 220px;
      text-align: justify;
    }

    p {
      /* padding-left: 220px; */
      text-align: justify;
    }
  </style>

  <!-- <script defer src="https://use.fontawesome.com/releases/v5.9.0/js/all.js"></script> -->
</head>

<body class='page page-about'>
  <div id="main-menu-mobile" class="main-menu-mobile">
    <ul>
      <li class="menu-item-about">
        <a href="./home.html">
          <span>Home</span>
        </a>
      </li>

      <li class="menu-item-people">
        <a href="./people.html">
          <span>People</span>
        </a>
      </li>

      <li class="menu-item-publications">
        <a href="./publication.html">
          <span>Publication</span>
        </a>
      </li>

      <li class="menu-item-software  active">
        <a href="./research.html">
          <span>Research</span>
        </a>
      </li>

      <li class="menu-item-software">
        <a href="./info.html">
          <span>Demos</span>
        </a>
      </li>
    </ul>
  </div>
  <div class="wrapper">
    <div class='header'>
      <div class="container">
        <h4 class="header-title">
          <a href="./home.html"><img src="./grouplogo.webp" style="max-width: 50%"></a>
          <!-- <a href="./home.html">Intelligent Multimedia Security Group</a> -->
        </h4>
        <div id="main-menu" class="main-menu">
          <ul>
            <li class="menu-item-about">
              <a href="./home.html">
                <span>Home</span>
              </a>
            </li>

            <li class="menu-item-people">
              <a href="./people.html">
                <span>People</span>
              </a>
            </li>

            <li class="menu-item-publications">
              <a href="./publication.html">
                <span>Publication</span>
              </a>
            </li>

            <li class="menu-item-software   active">
              <a href="./research.html">
                <span>Research</span>
              </a>
            </li>

            <li class="menu-item-software">
              <a href="./info.html">
                <span>Demos</span>
              </a>
            </li>
          </ul>
        </div>
        <button id="toggle-main-menu-mobile" class="hamburger hamburger--slider" role="presentation"
          aria-label="mobile menu trigger">
          <span class="hamburger-box">
            <span class="hamburger-inner"></span>
          </span>
        </button>
      </div>
    </div>


    <div class="container mt-2">
      <div class="row">

        <div class="col-md-6">
          <div class="media">
            <h4><a href="research/maskedface.html" target="_blank"><strong>Masked Face Analysis</strong></a>
            </h4>
            <a class="img-fluid" href="research/maskedface.html" target="_blank"><img src="./img/research2/masked.webp"
                width="100%"></a>
            <p>
              <!-- <div class="body"> -->
              Many real-world applications like video surveillance and urban governance need to address the recognition
              of masked faces. In this research, we build the first large-scale MAsked FAce dataset (MAFA) in the world
              and propose novel solutions（e.g., LLE-CNNs, identity-diversity inpainting, de-occlusion distillation) to
              alleviate the effect of large occlusions in understanding masked faces, which are published in CVPR, ACM
              MM and IEEE TCSVT.
              <!-- </div> -->
            </p>
          </div>
        </div>
        <div class="col-md-6">
          <div class="media">
            <h4><a href="research/lowresface.html" target="_blank"><strong>Low-Resolution Face Recognition</strong></a>
            </h4>
            <a class="img-fluid" href="research/lowresface.html" target="_blank"><img
                src="./img/research2/low_resolution.webp" width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              Low-resolution face images lack sufficient information required for recognition and have a certain degree of ambiguity. In this research, we propose cross-quality knowledge distillation framework and devise a series of effective algorithms (e.g., selective knowledge distillation, bridge distillation, few-shot distillation, hybrid order relational distillation, etc) to facilitate low-resolution face recognition in the wild, which are published in IEEE TIP, TCSVT, ACM MM and AAAI.
            </p>
            <!-- </div> -->
          </div>
        </div>
        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="./research/deeptracking.html" target="_blank"><strong>Tracking and Understanding Tiny Objects</strong></a></h4>
            <a href="./research/deeptracking.html" target="_blank"><img src="./img/research/deeptracking_indtro.png"
                class="img-fluid service-img border" width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              Tracking and understanding tiny objects plays an important role in many visual intelligence applications like video surveilance, military and medical. In this research, we aim to propose effective solutions to facilitate the robustness, accuracy and efficiency of deep visual tracking in the real-world scenarios like UAV and unmanned systems, which are publised in ACM MM, IEEE TNNLS and TIP, and have been deployed in some unmanned devices. Our solutions won the first places in two international challenges (VisDrone-SOT@ICCV2019 and Anti-UAV@CVPR2020).
            </p>
            <!-- </div> -->
          </div>
        </div>
        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="research/fightingdeepfake.html" target="_blank"><strong>Understanding and Fighting
                  Deepfake</strong></a></h4>
            <a href="research/fightingdeepfake.html" target="_blank"><img src="./img/research2/deepfake_detect.webp"
                class="img-fluid service-img border" width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              The rapid developping Deepfake technologies can easily generate large-scale high-fidelity fake videos, causing serious social influence. This research aims to discove the latent patterns inside Deepfake videos, proposes effective Deepfake detection approach by using temporal dropout 3DCNN and predictive representation learning, and develops explainable tool (XAI) to make the prediction more understandable for human. Our solution delivers state-of-the-art performance on popular benchmarks. These works are published in IEEE TIP, ACM TOMM, ACM MM and IJCAI.
            </p>
            <!-- </div> -->
            
          </div>
        </div>

        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="research/conlearning.html" target="_blank"><strong>Controllable Representation
                  Learning</strong></a></h4>
            <a href="research/conlearning.html" target="_blank"><img
                src="./img/research2/Controllable_Representation_Learning.png" class="img-fluid service-img border"
                width="100%"></a>
            <!-- <div class="body"> -->
            <p>
              The uncontrollability in real scenario seriously limits the ability of the representation learning, such as the unexplainability for human, the vulnerability to adversarial attack, the difficulty for learning from imperfect data, and other situations where the effective, fair and safe representation is very hard to learn. We work on constructing a series of controllable representation learning algorithms (e.g., selective-supervised contrastive learning, coupled-view learning, soft decision trees embedding, multi-granularity representation) to solve the above problems in real-world applications, which are publised in NeurIPS, CVPR, AAAI, ACM MM, IEEE TMM and IEEE TIP.
            </p>
            <!-- </div> -->
          </div>
        </div>
        <div class="col-md-6">
          <div class="service-block media">
            <h4><a href="#" target="_blank"><strong>Collaborative Machine Learning</strong></a></h4>
            <a href="#" target="_blank"><img src="./img/research2/collaborative_machine_learning.png"
                class="img-fluid service-img border" width="100%"></a>
            <p>
              When it comes to machine learning, the importance of data is self-evident, but most data is not wanted to be made public, a situation known as a "data island". In this research, we propose a controlled shared learning framework and design a series of effective algorithms (such as shared distillation, maximum local sharing, compression sharing) for machine learning under controlled conditions (data controlled, model controlled). These methods are suitable for various tasks (classification, semantic segmentation) and experiments on various datasets with excellent performance. which are published in IEEE TIP, MMSP, and so on.
            </p>
            <!-- </div> -->
          </div>
        </div>

      </div>

    </div>
  </div>



  <div class="footer">
    <div class="container">
      <div class="footer-text text-center">
        Copyright© 2023 IMSG | 地址: 北京市海淀区杏石口路益园文创基地C11东段 <br>
        <!-- Address: East Section C11, Yiyuan Wenchuang Base, Xingshikou Road, Haidian District, Beijing -->
        <img src="./footer.png" width="18px"> 京公网安备 11011602000736号 &nbsp;&nbsp;&nbsp;&nbsp;<a
          href="http://beian.miit.gov.cn" target="_blank" style="color: white">京ICP备20030229号</a>
      </div>
    </div>
  </div>

  <script type="text/javascript"
    src="https://statweb.stanford.edu/~candes/js/scripts.min.bf1e1f7ae8e03db5f012356e825843facdff51c0a559cb0d27fe2bbe1db405c2.js"></script>


  <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
    integrity="sha256-pasqAKBDmFT4eHoN2ndd6lN370kFiGUFyTiUHWhU7k8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.15.0/umd/popper.min.js"
    integrity="sha256-fTuUgtT7O2rqoImwjrhDgbXTKUwyxxujIMRIK7TbuNU=" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>
  <script>
    $(function () { $('[data-toggle="tooltip"]').tooltip() })
  </script>

</body>

</html>
